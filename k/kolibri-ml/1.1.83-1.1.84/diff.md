# Comparing `tmp/kolibri_ml-1.1.83-py3-none-any.whl.zip` & `tmp/kolibri_ml-1.1.84-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,10 +1,10 @@
-Zip file size: 1296017 bytes, number of entries: 699
+Zip file size: 1297742 bytes, number of entries: 700
 -rw-r--r--  2.0 unx       18 b- defN 23-Aug-03 22:02 kolibri/.env
--rw-r--r--  2.0 unx        7 b- defN 23-Aug-05 21:57 kolibri/VERSION
+-rw-r--r--  2.0 unx        7 b- defN 23-Aug-06 14:29 kolibri/VERSION
 -rw-r--r--  2.0 unx     4358 b- defN 23-Aug-03 20:53 kolibri/__init__.py
 -rw-r--r--  2.0 unx    16782 b- defN 23-Jul-09 11:29 kolibri/app.py
 -rw-r--r--  2.0 unx     3190 b- defN 23-Jul-09 11:29 kolibri/config.py
 -rw-r--r--  2.0 unx     1902 b- defN 23-Jul-09 11:29 kolibri/config_loader.py
 -rw-r--r--  2.0 unx     3814 b- defN 23-Aug-03 22:27 kolibri/default_configs.py
 -rw-r--r--  2.0 unx     5968 b- defN 23-Aug-03 20:53 kolibri/errors.py
 -rw-r--r--  2.0 unx      795 b- defN 23-Jul-09 11:29 kolibri/logger.py
@@ -465,41 +465,42 @@
 -rw-r--r--  2.0 unx     2651 b- defN 23-Jul-09 11:29 kolibri/samplers/data_sampler.py
 -rw-r--r--  2.0 unx     7780 b- defN 23-Jul-09 11:29 kolibri/samplers/smoteR.py
 -rw-r--r--  2.0 unx        0 b- defN 23-Jul-09 11:29 kolibri/scripts/__init__.py
 -rw-r--r--  2.0 unx      988 b- defN 23-Jul-09 11:29 kolibri/scripts/check_requirements.py
 -rw-r--r--  2.0 unx     1284 b- defN 23-Jul-09 11:29 kolibri/scripts/install_plugin_deps.py
 -rw-r--r--  2.0 unx       52 b- defN 23-Jul-09 11:29 kolibri/stopwords/__init__.py
 -rw-r--r--  2.0 unx     2016 b- defN 23-Jul-09 11:29 kolibri/stopwords/stp_wrd.py
--rw-r--r--  2.0 unx      495 b- defN 23-Aug-05 11:31 kolibri/synthetic_data/__init__.py
+-rw-r--r--  2.0 unx      713 b- defN 23-Aug-06 11:34 kolibri/synthetic_data/__init__.py
 -rw-r--r--  2.0 unx     3060 b- defN 23-Aug-03 20:53 kolibri/synthetic_data/anonymization.py
--rw-r--r--  2.0 unx    45818 b- defN 23-Aug-05 14:21 kolibri/synthetic_data/base.py
+-rw-r--r--  2.0 unx    45790 b- defN 23-Aug-06 11:03 kolibri/synthetic_data/base.py
 -rw-r--r--  2.0 unx    18063 b- defN 23-Aug-03 20:53 kolibri/synthetic_data/base_contraint.py
--rw-r--r--  2.0 unx    11071 b- defN 23-Aug-05 15:57 kolibri/synthetic_data/copulagan.py
+-rw-r--r--  2.0 unx    11107 b- defN 23-Aug-06 11:01 kolibri/synthetic_data/copulagan.py
 -rw-r--r--  2.0 unx    14946 b- defN 23-Aug-05 14:21 kolibri/synthetic_data/copulas.py
--rw-r--r--  2.0 unx     9468 b- defN 23-Aug-03 20:53 kolibri/synthetic_data/ctgan_synthesizer.py
+-rw-r--r--  2.0 unx     5656 b- defN 23-Aug-06 11:17 kolibri/synthetic_data/ctgan_synthesizer.py
 -rw-r--r--  2.0 unx    35479 b- defN 23-Aug-05 14:47 kolibri/synthetic_data/data_processor.py
 -rw-r--r--  2.0 unx    21083 b- defN 23-Aug-05 21:55 kolibri/synthetic_data/metadata.py
 -rw-r--r--  2.0 unx     7180 b- defN 23-Aug-03 20:53 kolibri/synthetic_data/single_table.py
+-rw-r--r--  2.0 unx     7174 b- defN 23-Aug-06 11:32 kolibri/synthetic_data/synthcity_lib.py
 -rw-r--r--  2.0 unx     3227 b- defN 23-Aug-05 16:08 kolibri/synthetic_data/synthpop.py
 -rw-r--r--  2.0 unx    10163 b- defN 23-Aug-05 06:42 kolibri/synthetic_data/utils.py
 -rw-r--r--  2.0 unx     1186 b- defN 23-Aug-05 11:04 kolibri/synthetic_data/benchmark/__init__.py
 -rw-r--r--  2.0 unx    15188 b- defN 23-Aug-05 06:42 kolibri/synthetic_data/benchmark/benchmark.py
--rw-r--r--  2.0 unx     6574 b- defN 23-Aug-05 19:59 kolibri/synthetic_data/benchmark/data.py
+-rw-r--r--  2.0 unx     6638 b- defN 23-Aug-06 10:50 kolibri/synthetic_data/benchmark/data.py
 -rw-r--r--  2.0 unx     3309 b- defN 23-Aug-03 20:53 kolibri/synthetic_data/benchmark/metrics.py
 -rw-r--r--  2.0 unx     2241 b- defN 23-Aug-05 18:27 kolibri/synthetic_data/benchmark/ml.py
 -rw-r--r--  2.0 unx     2051 b- defN 23-Aug-05 11:00 kolibri/synthetic_data/benchmark/privacy.py
--rw-r--r--  2.0 unx     4985 b- defN 23-Aug-03 20:53 kolibri/synthetic_data/benchmark/reporting.py
+-rw-r--r--  2.0 unx     6132 b- defN 23-Aug-06 12:02 kolibri/synthetic_data/benchmark/reporting.py
 -rw-r--r--  2.0 unx     2239 b- defN 23-Aug-05 08:41 kolibri/synthetic_data/benchmark/utility.py
--rw-r--r--  2.0 unx     4880 b- defN 23-Aug-05 07:10 kolibri/synthetic_data/benchmark/utils.py
+-rw-r--r--  2.0 unx     5464 b- defN 23-Aug-06 10:44 kolibri/synthetic_data/benchmark/utils.py
 -rw-r--r--  2.0 unx     1063 b- defN 23-Aug-05 15:35 kolibri/synthetic_data/benchmark/synthesizers/__init__.py
--rw-r--r--  2.0 unx     1992 b- defN 23-Aug-05 06:42 kolibri/synthetic_data/benchmark/synthesizers/base.py
+-rw-r--r--  2.0 unx     2022 b- defN 23-Aug-06 10:51 kolibri/synthetic_data/benchmark/synthesizers/base.py
 -rw-r--r--  2.0 unx     7232 b- defN 23-Aug-03 20:53 kolibri/synthetic_data/benchmark/synthesizers/generate.py
 -rw-r--r--  2.0 unx     1337 b- defN 23-Aug-03 20:53 kolibri/synthetic_data/benchmark/synthesizers/identity.py
 -rw-r--r--  2.0 unx     2114 b- defN 23-Aug-03 20:53 kolibri/synthetic_data/benchmark/synthesizers/independent.py
--rw-r--r--  2.0 unx     3491 b- defN 23-Aug-05 15:35 kolibri/synthetic_data/benchmark/synthesizers/sd.py
+-rw-r--r--  2.0 unx     5637 b- defN 23-Aug-06 11:53 kolibri/synthetic_data/benchmark/synthesizers/sd.py
 -rw-r--r--  2.0 unx     1665 b- defN 23-Aug-03 20:53 kolibri/synthetic_data/benchmark/synthesizers/uniform.py
 -rw-r--r--  2.0 unx       66 b- defN 23-Jul-09 11:29 kolibri/task/__init__.py
 -rw-r--r--  2.0 unx     7685 b- defN 23-Jul-09 11:29 kolibri/task/dnn_estimator.py
 -rw-r--r--  2.0 unx      104 b- defN 23-Jul-09 11:29 kolibri/task/audio/__init__.py
 -rw-r--r--  2.0 unx     9853 b- defN 23-Jul-09 11:29 kolibri/task/audio/base_model.py
 -rw-r--r--  2.0 unx       75 b- defN 23-Jul-09 11:29 kolibri/task/audio/classification/__init__.py
 -rw-r--r--  2.0 unx     3231 b- defN 23-Jul-09 11:29 kolibri/task/audio/classification/dnn_audio_estimator.py
@@ -689,13 +690,13 @@
 -rw-r--r--  2.0 unx     1128 b- defN 23-Jul-09 11:29 tests/synthesizer/losses/test_conditional_loss.py
 -rw-r--r--  2.0 unx      812 b- defN 23-Jul-09 11:29 tests/synthesizer/losses/test_gradient_penalty.py
 -rw-r--r--  2.0 unx        0 b- defN 23-Jul-09 11:29 tests/synthesizer/models/__init__.py
 -rw-r--r--  2.0 unx     1214 b- defN 23-Jul-09 11:29 tests/synthesizer/models/test_critic.py
 -rw-r--r--  2.0 unx     4972 b- defN 23-Jul-09 11:29 tests/synthesizer/models/test_generator.py
 -rw-r--r--  2.0 unx        0 b- defN 23-Jul-09 11:29 tests/synthesizer/synthesizer/__init__.py
 -rw-r--r--  2.0 unx     4090 b- defN 23-Jul-09 11:29 tests/synthesizer/synthesizer/test_synthesizer.py
--rw-r--r--  2.0 unx    34572 b- defN 23-Aug-05 21:58 kolibri_ml-1.1.83.dist-info/LICENCE.txt
--rw-r--r--  2.0 unx     4885 b- defN 23-Aug-05 21:58 kolibri_ml-1.1.83.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Aug-05 21:58 kolibri_ml-1.1.83.dist-info/WHEEL
--rw-r--r--  2.0 unx       14 b- defN 23-Aug-05 21:58 kolibri_ml-1.1.83.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx    67912 b- defN 23-Aug-05 21:58 kolibri_ml-1.1.83.dist-info/RECORD
-699 files, 4494043 bytes uncompressed, 1186243 bytes compressed:  73.6%
+-rw-r--r--  2.0 unx    34572 b- defN 23-Aug-06 14:30 kolibri_ml-1.1.84.dist-info/LICENCE.txt
+-rw-r--r--  2.0 unx     4885 b- defN 23-Aug-06 14:30 kolibri_ml-1.1.84.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Aug-06 14:30 kolibri_ml-1.1.84.dist-info/WHEEL
+-rw-r--r--  2.0 unx       14 b- defN 23-Aug-06 14:30 kolibri_ml-1.1.84.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx    68008 b- defN 23-Aug-06 14:30 kolibri_ml-1.1.84.dist-info/RECORD
+700 files, 4501698 bytes uncompressed, 1187814 bytes compressed:  73.6%
```

## zipnote {}

```diff
@@ -1434,14 +1434,17 @@
 
 Filename: kolibri/synthetic_data/metadata.py
 Comment: 
 
 Filename: kolibri/synthetic_data/single_table.py
 Comment: 
 
+Filename: kolibri/synthetic_data/synthcity_lib.py
+Comment: 
+
 Filename: kolibri/synthetic_data/synthpop.py
 Comment: 
 
 Filename: kolibri/synthetic_data/utils.py
 Comment: 
 
 Filename: kolibri/synthetic_data/benchmark/__init__.py
@@ -2076,23 +2079,23 @@
 
 Filename: tests/synthesizer/synthesizer/__init__.py
 Comment: 
 
 Filename: tests/synthesizer/synthesizer/test_synthesizer.py
 Comment: 
 
-Filename: kolibri_ml-1.1.83.dist-info/LICENCE.txt
+Filename: kolibri_ml-1.1.84.dist-info/LICENCE.txt
 Comment: 
 
-Filename: kolibri_ml-1.1.83.dist-info/METADATA
+Filename: kolibri_ml-1.1.84.dist-info/METADATA
 Comment: 
 
-Filename: kolibri_ml-1.1.83.dist-info/WHEEL
+Filename: kolibri_ml-1.1.84.dist-info/WHEEL
 Comment: 
 
-Filename: kolibri_ml-1.1.83.dist-info/top_level.txt
+Filename: kolibri_ml-1.1.84.dist-info/top_level.txt
 Comment: 
 
-Filename: kolibri_ml-1.1.83.dist-info/RECORD
+Filename: kolibri_ml-1.1.84.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## kolibri/VERSION

```diff
@@ -1 +1 @@
-1.1.83
+1.1.84
```

## kolibri/synthetic_data/__init__.py

```diff
@@ -1,15 +1,19 @@
 """ lite package that contains model presets."""
 
 from kolibri.synthetic_data.single_table import SingleTablePreset, GaussianCopulaSynthesizer
 from kolibri.synthetic_data.copulagan import CopulaGANSynthesizer
 from kolibri.synthetic_data.ctgan_synthesizer import CTGANSynthesizer
 from kolibri.synthetic_data.synthpop import SynthpopSynthesizer
+from kolibri.synthetic_data.synthcity_lib import SynthcityBNSynthesizer, SynthcityAdGanynthesizer, SynthcityTVAESynthesizer
 
 __all__ = (
     'SingleTablePreset',
     'CTGANSynthesizer',
     'GaussianCopulaSynthesizer',
     'CopulaGANSynthesizer',
-    'SynthpopSynthesizer'
+    'SynthpopSynthesizer',
+    'SynthcityBNSynthesizer',
+    'SynthcityAdGanynthesizer',
+    'SynthcityTVAESynthesizer'
 
 )
```

## kolibri/synthetic_data/base.py

```diff
@@ -449,15 +449,15 @@
             warnings.warn(
                 'This model has already been fitted. To use the new preprocessed data, '
                 "please refit the model using 'fit' or 'fit_processed_data'."
             )
 
         return self._preprocess(data)
 
-    def _fit(self, processed_data, epochs=None):
+    def _fit(self, processed_data):
         """Fit the model to the table.
 
         Args:
             processed_data (pandas.DataFrame):
                 Data to be learned.
         """
         raise NotImplementedError()
@@ -465,15 +465,15 @@
     def fit_processed_data(self, processed_data, epochs):
         """Fit this model to the transformed data.
 
         Args:
             processed_data (pandas.DataFrame):
                 The transformed data used to fit the model to.
         """
-        self._fit(processed_data, epochs=epochs)
+        self._fit(processed_data)
         self._fitted = True
         self._fitted_date = datetime.datetime.today().strftime('%Y-%m-%d')
         try:
             self._fitted_sd_version = pkg_resources.get_distribution('kolibri-ml').version
         except:
             import kolibri
             self._fitted_sd_version=kolibri.__version__
```

## kolibri/synthetic_data/copulagan.py

```diff
@@ -133,20 +133,21 @@
             generator_lr=generator_lr,
             discriminator_lr=discriminator_lr,
             batch_size=batch_size,
             log_frequency=log_frequency,
             verbose=verbose,
             pac=pac,
             cuda=cuda,
+            epochs=epochs
         )
 
         validate_numerical_distributions(numerical_distributions, self.metadata.columns)
         self.numerical_distributions = numerical_distributions or {}
         self.default_distribution = default_distribution or 'beta'
-
+        self.epochs=epochs
         self._default_distribution = GaussianCopulaSynthesizer.get_distribution_class(
             default_distribution or 'beta'
         )
         self._numerical_distributions = {
             field: GaussianCopulaSynthesizer.get_distribution_class(distribution)
             for field, distribution in self.numerical_distributions.items()
         }
@@ -171,30 +172,30 @@
 
             else:
                 sdtypes[column] = sdtype or 'categorical' or 'category'
                 transformers[column] = None
 
         return {'transformers': transformers, 'sdtypes': sdtypes}
 
-    def _fit(self, processed_data, epochs):
+    def _fit(self, processed_data):
         """Fit the model to the table.
 
         Args:
             processed_data (pandas.DataFrame):
                 Data to be learned.
         """
         log_numerical_distributions_error(
             self.numerical_distributions, processed_data.columns, LOGGER)
 
         gaussian_normalizer_config = self._create_gaussian_normalizer_config(processed_data)
         self._gaussian_normalizer_hyper_transformer = rdt.HyperTransformer()
         self._gaussian_normalizer_hyper_transformer.set_config(gaussian_normalizer_config)
         processed_data = self._gaussian_normalizer_hyper_transformer.fit_transform(processed_data)
 
-        super()._fit(processed_data, epochs)
+        super()._fit(processed_data)
 
     def _sample(self, num_rows, conditions=None):
         """Sample the indicated number of rows from the model.
 
         Args:
             num_rows (int):
                 Amount of rows to sample.
```

## kolibri/synthetic_data/ctgan_synthesizer.py

```diff
@@ -58,15 +58,15 @@
             If ``False``, do not use cuda at all.
     """
 
     _model_sdtype_transformers = {'categorical': None}
 
     def __init__(self, metadata, enforce_min_max_values=True, enforce_rounding=True, locales=None,
                  embedding_dim=128, generator_dim=(256, 256), discriminator_dim=(256, 256),
-                 generator_lr=2e-4, discriminator_lr=2e-4,batch_size=100,
+                 generator_lr=2e-4, discriminator_lr=2e-4,batch_size=100, epochs=10,
                  log_frequency=True, verbose=False, pac=10, cuda=True):
 
         super().__init__(
             metadata=metadata,
             enforce_min_max_values=enforce_min_max_values,
             enforce_rounding=enforce_rounding,
             locales=locales
@@ -89,25 +89,25 @@
             'discriminator_dim': discriminator_dim,
             'generator_lr': generator_lr,
             'discriminator_lr': discriminator_lr,
             'batch_size': batch_size,
             'log_frequency': log_frequency,
             'pac': pac
         }
-
-    def _fit(self, processed_data, epochs=100):
+        self.epochs=epochs
+    def _fit(self, processed_data):
         """Fit the model to the table.
 
         Args:
             processed_data (pandas.DataFrame):
                 Data to be learned.
         """
         discrete_columns = detect_discrete_columns(self.get_metadata(), processed_data)
         self._model = synthetic.CTGANSynthesizer(**self._model_kwargs)
-        self._model.train(processed_data, discrete_columns=discrete_columns, epochs=epochs)
+        self._model.train(processed_data, discrete_columns=discrete_columns, epochs=self.epochs)
 
     def _sample(self, num_rows, conditions=None):
         """Sample the indicated number of rows from the model.
 
         Args:
             num_rows (int):
                 Amount of rows to sample.
@@ -120,102 +120,7 @@
             pandas.DataFrame:
                 Sampled data.
         """
         if conditions is None:
             return self._model.sample(num_rows)
 
         raise NotImplementedError("CTGANSynthesizer doesn't support conditional sampling.")
-
-
-class TVAESynthesizer(BaseSingleTableSynthesizer):
-    """Model wrapping ``TVAE`` model.
-
-    Args:
-        metadata (sdv.metadata.SingleTableMetadata):
-            Single table metadata representing the data that this synthesizer_name will be used for.
-        enforce_min_max_values (bool):
-            Specify whether or not to clip the data returned by ``reverse_transform`` of
-            the numerical transformer, ``FloatFormatter``, to the min and max values seen
-            during ``fit``. Defaults to ``True``.
-        enforce_rounding (bool):
-            Define rounding scheme for ``numerical`` columns. If ``True``, the data returned
-            by ``reverse_transform`` will be rounded as in the original data. Defaults to ``True``.
-        embedding_dim (int):
-            Size of the random sample passed to the Generator. Defaults to 128.
-        compress_dims (tuple or list of ints):
-            Size of each hidden layer in the encoder. Defaults to (128, 128).
-        decompress_dims (tuple or list of ints):
-           Size of each hidden layer in the decoder. Defaults to (128, 128).
-        l2scale (int):
-            Regularization term. Defaults to 1e-5.
-        batch_size (int):
-            Number of data samples to process in each step.
-        epochs (int):
-            Number of training epochs. Defaults to 300.
-        loss_factor (int):
-            Multiplier for the reconstruction error. Defaults to 2.
-        cuda (bool or str):
-            If ``True``, use CUDA. If a ``str``, use the indicated device.
-            If ``False``, do not use cuda at all.
-    """
-
-    _model_sdtype_transformers = {'categorical': None}
-
-    def __init__(self, metadata, enforce_min_max_values=True, enforce_rounding=True,
-                 embedding_dim=128, compress_dims=(128, 128), decompress_dims=(128, 128),
-                 l2scale=1e-5, batch_size=500, epochs=300, loss_factor=2, cuda=True):
-
-        super().__init__(
-            metadata=metadata,
-            enforce_min_max_values=enforce_min_max_values,
-            enforce_rounding=enforce_rounding,
-        )
-        self.embedding_dim = embedding_dim
-        self.compress_dims = compress_dims
-        self.decompress_dims = decompress_dims
-        self.l2scale = l2scale
-        self.batch_size = batch_size
-        self.epochs = epochs
-        self.loss_factor = loss_factor
-        self.cuda = cuda
-
-        self._model_kwargs = {
-            'embedding_dim': embedding_dim,
-            'compress_dims': compress_dims,
-            'decompress_dims': decompress_dims,
-            'l2scale': l2scale,
-            'batch_size': batch_size,
-            'epochs': epochs,
-            'loss_factor': loss_factor,
-            'cuda': cuda
-        }
-
-    def _fit(self, processed_data):
-        """Fit the model to the table.
-
-        Args:
-            processed_data (pandas.DataFrame):
-                Data to be learned.
-        """
-        discrete_columns = detect_discrete_columns(self.get_metadata(), processed_data)
-        self._model = TVAE(**self._model_kwargs)
-        self._model.fit(processed_data, discrete_columns=discrete_columns)
-
-    def _sample(self, num_rows, conditions=None):
-        """Sample the indicated number of rows from the model.
-
-        Args:
-            num_rows (int):
-                Amount of rows to sample.
-            conditions (dict):
-                If specified, this dictionary maps column names to the column
-                value. Then, this method generates ``num_rows`` samples, all of
-                which are conditioned on the given variables.
-
-        Returns:
-            pandas.DataFrame:
-                Sampled data.
-        """
-        if conditions is None:
-            return self._model.sample(num_rows)
-
-        raise NotImplementedError("TVAESynthesizer doesn't support conditional sampling.")
```

## kolibri/synthetic_data/benchmark/data.py

```diff
@@ -68,26 +68,27 @@
         output_dict = json.load(metadata_file)
 
 
     return data, output_dict
 
 def _synthesize_data(synthesizer_dict, real_data, metadata):
     synthesizer = synthesizer_dict['synthesizer_name']
+    synthesizer_kw=synthesizer_dict['kwargs']
     assert issubclass(
         synthesizer, BaselineSynthesizer), '`synthesizer_name` must be a synthesizer_name class'
 
     synthesizer_object = synthesizer()
     get_synthesizer = synthesizer_object.get_trained_synthesizer
     sample_from_synthesizer = synthesizer_object.sample_from_synthesizer
     data = real_data.copy()
     num_samples = len(data)
 
     tracemalloc.start()
     now = datetime.utcnow()
-    synthesizer_obj = get_synthesizer(data, metadata)
+    synthesizer_obj = get_synthesizer(data, metadata, **synthesizer_kw)
     try:
         synthesizer_size = len(pickle.dumps(synthesizer_obj)) / N_BYTES_IN_MB
     except:
         synthesizer_size = sys.getsizeof(synthesizer_obj)
     train_now = datetime.utcnow()
     synthetic_data = sample_from_synthesizer(synthesizer_obj, num_samples)
     sample_now = datetime.utcnow()
```

## kolibri/synthetic_data/benchmark/reporting.py

```diff
@@ -1,14 +1,15 @@
 
 from sdmetrics.reports.utils import get_column_pair_plot
 from sdmetrics.reports.single_table import QualityReport
 import os
 from sdmetrics.reports.utils import get_column_plot
 import plotly.io as pio
 from plotly.subplots import make_subplots
+import pandas as pd
 def closest_factors(n):
     closest_difference = n
     factor1 = 1
     factor2 = n
 
     for i in range(1, int(n**0.5) + 1):
         if n % i == 0:
@@ -131,7 +132,30 @@
 
         pio.write_image(worst_column_pair_fig, os.path.join(base_report_folder, "worst_column_pair_fig.png"), format='png',
                         width=800,
                         height=600)
 
 
 
+def generate_quality_report_benchmark(datasets, synthetizes, repo):
+    out = []
+    from sdmetrics.reports.single_table import QualityReport
+    for dataset in datasets:
+        for fn in synthetizes:
+            print(dataset, fn)
+            print(f'{repo}/original_data/{dataset}_train.csv')
+            print(f'{repo}/{dataset}_{fn}.csv.gz')
+            trn = pd.read_csv(f'{repo}/original_data/{dataset}_train.csv')
+            syn = pd.read_csv(f'{repo}/synthetic_data/{fn}_{dataset}.csv')
+            metadata = {
+                "columns": {c: {"sdtype": "categorical" if trn[c].dtype == 'object' else 'numerical'} for c in trn}}
+            my_report = QualityReport()
+            my_report.generate(trn, syn, metadata)
+            out += [pd.DataFrame({
+                'dataset': [dataset],
+                'synthesizer': [fn],
+                'Column Shapes': [my_report.get_details("Column Shapes")["Quality Score"].mean()],
+                'Column Pair Trends': [my_report.get_details("Column Pair Trends")["Quality Score"].mean()],
+            })]
+    sdv = pd.concat(out).reset_index(drop=True)
+
+    return sdv
```

## kolibri/synthetic_data/benchmark/utils.py

```diff
@@ -47,25 +47,35 @@
     """
     synthesizers = [] if synthesizers is None else synthesizers
     if not isinstance(synthesizers, list):
         raise TypeError('`synthesizers_dict` must be a list.')
 
     synthesizers_dicts = []
     for synthesizer in synthesizers:
+        synthesizer_kw={}
         if isinstance(synthesizer, str):
             baselines = BaselineSynthesizer.get_subclasses(include_parents=True)
             if synthesizer in baselines:
                 LOGGER.info('Trying to import synthesizer_name by name.')
                 synthesizer = baselines[synthesizer]
             else:
                 raise Exception(f'Unknown synthesizer_name {synthesizer}') from None
-
+        elif isinstance(synthesizer, dict):
+            synthesizer_name = list(synthesizer.keys())[0]
+            synthesizer_kw=synthesizer[synthesizer_name]
+            baselines = BaselineSynthesizer.get_subclasses(include_parents=True)
+            if synthesizer_name in baselines:
+                LOGGER.info('Trying to import synthesizer_name by name.')
+                synthesizer = baselines[synthesizer_name]
+            else:
+                raise Exception(f'Unknown synthesizer_name {synthesizer}') from None
         synthesizers_dicts.append({
             'name': getattr(synthesizer, '__name__', 'undefined'),
             'synthesizer_name': synthesizer,
+            'kwargs': synthesizer_kw
         })
 
     return synthesizers_dicts
 
 
 def get_size_of(obj, obj_ids=None):
     """Get the memory used by a given object in bytes.
```

## kolibri/synthetic_data/benchmark/synthesizers/base.py

```diff
@@ -17,30 +17,30 @@
         synthesizers = []
         for _, subclass in subclasses.items():
             if abc.ABC not in subclass.__bases__:
                 synthesizers.append(subclass)
 
         return synthesizers
 
-    def get_trained_synthesizer(self, data, metadata):
+    def get_trained_synthesizer(self, data, metadata, **kwargs):
         """Get a synthesizer_name that has been trained on the provided data and metadata.
 
         Args:
             data (pandas.DataFrame):
                 The data to train on.
             metadata (dict):
                 The metadata dictionary.
 
         Returns:
             obj:
                 The synthesizer_name object.
         """
 #        metadata_class = TableMetadata()
 #        metadata = metadata_class.load_from_dict(metadata)
-        return self._get_trained_synthesizer(data, metadata)
+        return self._get_trained_synthesizer(data, metadata, **kwargs)
 
     def sample_from_synthesizer(self, synthesizer, n_samples):
         """Sample data from the provided synthesizer_name.
 
         Args:
             synthesizer (obj):
                 The synthesizer_name object to sample data from.
@@ -50,13 +50,13 @@
         Returns:
             pandas.DataFrame or dict:
                 The sampled data. If single-table, should be a DataFrame. If multi-table,
                 should be a dict mapping table name to DataFrame.
         """
         return self._sample_from_synthesizer(synthesizer, n_samples)
 
-    def _get_trained_synthesizer(self, data, metadata):
+    def _get_trained_synthesizer(self, data, metadata, **kwargs):
         raise NotImplementedError
 
 
     def _sample_from_synthesizer(self, synthesizer, n_samples):
         raise NotImplementedError
```

## kolibri/synthetic_data/benchmark/synthesizers/sd.py

```diff
@@ -8,30 +8,30 @@
 
 class FastMLPreset(BaselineSynthesizer):
     """Model wrapping the ``FastMLPreset`` model."""
 
     _MODEL = None
     _MODEL_KWARGS = None
 
-    def _get_trained_synthesizer(self, data, metadata):
+    def _get_trained_synthesizer(self, data, metadata, **model_kwargs):
         model = synthetic_data.SingleTablePreset(name='FAST_ML', metadata=metadata)
         model.fit(data)
 
         return model
 
     def _sample_from_synthesizer(self, synthesizer, n_samples):
         return synthesizer.sample(n_samples)
 
 class SDVTabularSynthesizer(BaselineSynthesizer, abc.ABC):
     """Base class for single-table models."""
 
     _MODEL = None
     _MODEL_KWARGS = None
 
-    def _get_trained_synthesizer(self, data, metadata):
+    def _get_trained_synthesizer(self, data, metadata,  **model_kwargs):
         LOGGER.info('Fitting %s', self.__class__.__name__)
         model_kwargs = self._MODEL_KWARGS.copy() if self._MODEL_KWARGS else {}
         model = self._MODEL(metadata=metadata, **model_kwargs)
         model.fit(data)
         return model
 
     def _sample_from_synthesizer(self, synthesizer, n_samples):
@@ -49,17 +49,17 @@
     """Model wrapping the ``CTGANSynthesizer`` model."""
 
     _MODEL = synthetic_data.CTGANSynthesizer
 
 
     _MODEL_KWARGS = None
 
-    def _get_trained_synthesizer(self, data, metadata):
+    def _get_trained_synthesizer(self, data, metadata, **model_kwargs):
         LOGGER.info('Fitting %s', self.__class__.__name__)
-        model_kwargs = self._MODEL_KWARGS.copy() if self._MODEL_KWARGS else {}
+ #       model_kwargs = self._MODEL_KWARGS.copy() if self._MODEL_KWARGS else {}
         model = self._MODEL(metadata=metadata, **model_kwargs)
         model.fit(data)
         return model
 
     def _sample_from_synthesizer(self, synthesizer, n_samples):
         LOGGER.info('Sampling %s', self.__class__.__name__)
         return synthesizer.sample(n_samples)
@@ -68,31 +68,87 @@
     """Model wrapping the ``CTGANSynthesizer`` model."""
 
     _MODEL = synthetic_data.SynthpopSynthesizer
 
 
     _MODEL_KWARGS = None
 
-    def _get_trained_synthesizer(self, data, metadata):
+    def _get_trained_synthesizer(self, data, metadata, **model_kwargs):
         LOGGER.info('Fitting %s', self.__class__.__name__)
         model_kwargs = self._MODEL_KWARGS.copy() if self._MODEL_KWARGS else {}
         model = self._MODEL(metadata=metadata, **model_kwargs)
         model.fit(data)
         return model
 
     def _sample_from_synthesizer(self, synthesizer, n_samples):
         LOGGER.info('Sampling %s', self.__class__.__name__)
         return synthesizer.sample(n_samples)
 
+class SynthcityBNSynthesizer(SDVTabularSynthesizer):
+    """Model wrapping the ``CTGANSynthesizer`` model."""
+
+    _MODEL = synthetic_data.SynthcityBNSynthesizer
+
+
+    _MODEL_KWARGS = None
+
+    def _get_trained_synthesizer(self, data, metadata, **model_kwargs):
+        LOGGER.info('Fitting %s', self.__class__.__name__)
+ #       model_kwargs = self._MODEL_KWARGS.copy() if self._MODEL_KWARGS else {}
+        model = self._MODEL(metadata=metadata, **model_kwargs)
+        model.fit(data)
+        return model
+
+    def _sample_from_synthesizer(self, synthesizer, n_samples):
+        LOGGER.info('Sampling %s', self.__class__.__name__)
+        return synthesizer.sample(n_samples).data
+
+class SynthcityAdGanynthesizer(SDVTabularSynthesizer):
+    """Model wrapping the ``CTGANSynthesizer`` model."""
+
+    _MODEL = synthetic_data.SynthcityAdGanynthesizer
+
+
+    _MODEL_KWARGS = None
+
+    def _get_trained_synthesizer(self, data, metadata, **model_kwargs):
+        LOGGER.info('Fitting %s', self.__class__.__name__)
+ #       model_kwargs = self._MODEL_KWARGS.copy() if self._MODEL_KWARGS else {}
+        model = self._MODEL(metadata=metadata, **model_kwargs)
+        model.fit(data)
+        return model
+
+    def _sample_from_synthesizer(self, synthesizer, n_samples):
+        LOGGER.info('Sampling %s', self.__class__.__name__)
+        return synthesizer.sample(n_samples).data
+
+class SynthcityTVAESynthesizer(SDVTabularSynthesizer):
+    """Model wrapping the ``CTGANSynthesizer`` model."""
+
+    _MODEL = synthetic_data.SynthcityTVAESynthesizer
+
+
+    _MODEL_KWARGS = None
+
+    def _get_trained_synthesizer(self, data, metadata, **model_kwargs):
+        LOGGER.info('Fitting %s', self.__class__.__name__)
+ #       model_kwargs = self._MODEL_KWARGS.copy() if self._MODEL_KWARGS else {}
+        model = self._MODEL(metadata=metadata, **model_kwargs)
+        model.fit(data)
+        return model
+
+    def _sample_from_synthesizer(self, synthesizer, n_samples):
+        LOGGER.info('Sampling %s', self.__class__.__name__)
+        return synthesizer.sample(n_samples).data
 
 class CopulaGANSynthesizer(SDVTabularSynthesizer):
     """Model wrapping the ``CopulaGANSynthesizer`` model."""
 
-    def _get_trained_synthesizer(self, data, metadata):
-        model_kwargs = self._MODEL_KWARGS.copy() if self._MODEL_KWARGS else {}
+    def _get_trained_synthesizer(self, data, metadata,  **model_kwargs):
+#        model_kwargs = self._MODEL_KWARGS.copy() if self._MODEL_KWARGS else {}
 #        model_kwargs.setdefault('cuda', select_device())
         LOGGER.info('Fitting %s with kwargs %s', self.__class__.__name__, model_kwargs)
         model = self._MODEL(metadata=metadata, **model_kwargs)
         model.fit(data)
         return model
 
     def _sample_from_synthesizer(self, synthesizer, n_samples):
```

## Comparing `kolibri_ml-1.1.83.dist-info/LICENCE.txt` & `kolibri_ml-1.1.84.dist-info/LICENCE.txt`

 * *Files identical despite different names*

## Comparing `kolibri_ml-1.1.83.dist-info/METADATA` & `kolibri_ml-1.1.84.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: kolibri-ml
-Version: 1.1.83
+Version: 1.1.84
 Summary: Deep Learning and more NLP toolkit
 Home-page: 
 Author: Mohamed Ben Haddou
 Author-email: mbenhaddou@mentis.io
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Operating System :: OS Independent
 Classifier: Development Status :: 4 - Beta
@@ -29,23 +29,23 @@
 Requires-Dist: networkx
 Requires-Dist: dtreeviz
 Requires-Dist: httpcore
 Requires-Dist: httpx
 Requires-Dist: httpx[http2]
 Requires-Dist: xlsxwriter
 Provides-Extra: all
+Requires-Dist: pyLDAvis ; extra == 'all'
 Requires-Dist: dateparser ; extra == 'all'
+Requires-Dist: gensim ; extra == 'all'
+Requires-Dist: wordcloud ; extra == 'all'
 Requires-Dist: ipywidgets ; extra == 'all'
-Requires-Dist: pyLDAvis ; extra == 'all'
+Requires-Dist: eml-parser ; extra == 'all'
 Requires-Dist: tensorflow (==2.8.0) ; extra == 'all'
-Requires-Dist: gensim ; extra == 'all'
 Requires-Dist: sonopy ; extra == 'all'
 Requires-Dist: fasttext ; extra == 'all'
-Requires-Dist: eml-parser ; extra == 'all'
-Requires-Dist: wordcloud ; extra == 'all'
 Provides-Extra: audio
 Requires-Dist: sonopy ; extra == 'audio'
 Provides-Extra: dnn
 Requires-Dist: tensorflow (==2.8.0) ; extra == 'dnn'
 Provides-Extra: nlp
 Requires-Dist: gensim ; extra == 'nlp'
 Requires-Dist: fasttext ; extra == 'nlp'
```

## Comparing `kolibri_ml-1.1.83.dist-info/RECORD` & `kolibri_ml-1.1.84.dist-info/RECORD`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 kolibri/.env,sha256=aTGCLQU1hQapds_lZrqczNPt3lbKv_aYKYE2Dl6iso0,18
-kolibri/VERSION,sha256=LebqwRZ3Ejirscd5bBsDrtjgLp0AvfOB2Mvddyu32wE,7
+kolibri/VERSION,sha256=7Po7T8tLofaTZFO5t_5S-pYN-2xumFIAB0EkaHw8T9o,7
 kolibri/__init__.py,sha256=mwGSkniI5XxmXMotgoe9P-jbkM35WtVsyO1uck-TDFg,4358
 kolibri/app.py,sha256=b_vLL8hIcbXgW_F-zOQfllebEiN-VdHsN7nEivYkZBA,16782
 kolibri/config.py,sha256=L1xrnHExgtg3gjE-pl67-BsOTJCtd9a-Gk8cG9FOo6M,3190
 kolibri/config_loader.py,sha256=gsdbv6fd6DU0HHd8aSOOMnOJL5dZJy8_pP2fqBWH_os,1902
 kolibri/default_configs.py,sha256=dGMN3ps9j_GD5C2KVWN5kFhVsIRHY8j5m4LsM3d4Gto,3814
 kolibri/errors.py,sha256=w4CWaoHWprc4NwaG9OmG0QKy8TsjzW40wx6x_p24dT8,5968
 kolibri/logger.py,sha256=bfFKEoKSshW41L2TCOTRDM03uP0RKJJ6ksyjToYaoYc,795
@@ -464,41 +464,42 @@
 kolibri/samplers/data_sampler.py,sha256=E1baN6v4xiLZnvLsyGOYe6YZEi95yCvYH9uXa7WNnpA,2651
 kolibri/samplers/smoteR.py,sha256=Th0uUXoFoSxNtMsWjLcEljeZ3iKXc7bbMm-0899NM1c,7780
 kolibri/scripts/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 kolibri/scripts/check_requirements.py,sha256=vkXTcHAycdLwrcsmrNRFYN5P1W29jYjDVoqEcofGlXE,988
 kolibri/scripts/install_plugin_deps.py,sha256=R2a1ntBiAiDoWylg6WXndRanOoyVEbpOd9_MS02zxf8,1284
 kolibri/stopwords/__init__.py,sha256=Tf5aza_sJkBdVAZOrYZd8N6R_Mk_8uy2UhoMnpm5NRQ,52
 kolibri/stopwords/stp_wrd.py,sha256=xdNBdBu2C5HoarWEzFeydr9BpQEt_A5zFe-KCu4hkaU,2016
-kolibri/synthetic_data/__init__.py,sha256=bQcGicM--cTHq9sjR7ShLRji-PVTpqGJvcDATi7A3Zc,495
+kolibri/synthetic_data/__init__.py,sha256=tKZNWwjHJt5xmb3t7eOdV6k_Hr4Nd3hIIPMX3xi4QwM,713
 kolibri/synthetic_data/anonymization.py,sha256=vCpZFS-l9ZsWg8Si6ht3VCyHetFNR3QsWKZpzxd4liA,3060
-kolibri/synthetic_data/base.py,sha256=dLLF15GuDK9znxuFoZVhjo0hLQiCtwS3kn0N1unEAMY,45818
+kolibri/synthetic_data/base.py,sha256=X125TPEdUsAMlBMOJfW6xgEa-PffWWoKODl2wCO8020,45790
 kolibri/synthetic_data/base_contraint.py,sha256=hB7OuFde0rDDYdO4u4I5orIJWZQAQmrSpd3-EE7ZmYk,18063
-kolibri/synthetic_data/copulagan.py,sha256=f6OqW69dNcS3HN13Nsk1pO8nztq_7CBis67aW-B3cJ4,11071
+kolibri/synthetic_data/copulagan.py,sha256=eV91SPj1NLl9i0QIy35uCeP8LEpr_QClnwOOh_qZs28,11107
 kolibri/synthetic_data/copulas.py,sha256=kjjZ-uh8NG_3nG8tDpeTnGjwoZgPUYZD7wnzg59u99Y,14946
-kolibri/synthetic_data/ctgan_synthesizer.py,sha256=jT1BP4XaxGTEqDEwjh6fwWbPvI0JU-HLETw9kJVwZyc,9468
+kolibri/synthetic_data/ctgan_synthesizer.py,sha256=uKG0UQRqQqABJ5Gu7jBCRys3xoQE4DbjwolnQJizjqQ,5656
 kolibri/synthetic_data/data_processor.py,sha256=6e46FcOZXDXEvfBwUo_U33Ehd3IFiqINv4YkE2Z8pqg,35479
 kolibri/synthetic_data/metadata.py,sha256=2UesH8epcyhidk3K_qoR6fBH9aBYbe6QjYLQXfNET6E,21083
 kolibri/synthetic_data/single_table.py,sha256=CB7KFUB539JMVXvOjUTIOMAHYEgohGPLubECUYVp-5U,7180
+kolibri/synthetic_data/synthcity_lib.py,sha256=zU8g4zCOTF5bN9tS7QwrCwxFhooKNTnUL0B_jys4b4E,7174
 kolibri/synthetic_data/synthpop.py,sha256=dGyRjkH2n6eSRTEptaJA8I93Q79ygkT5esiRwUQfOr8,3227
 kolibri/synthetic_data/utils.py,sha256=1jNPZpMEkF4TcHXQqUiwnxWzy0sTg7liW_e-qo05DzU,10163
 kolibri/synthetic_data/benchmark/__init__.py,sha256=aiqLsRMgabuatrfpJnq1jqd009p9gj7lZJRKVMkqUpg,1186
 kolibri/synthetic_data/benchmark/benchmark.py,sha256=b6ex4d8tLA-JgZZbQbIu5CFr0d6t7Yvf3uKEY47fIKk,15188
-kolibri/synthetic_data/benchmark/data.py,sha256=-8VFRl5s7RhII5TKWImDxHoz4FxKBKkSoSTxlAxcrmE,6574
+kolibri/synthetic_data/benchmark/data.py,sha256=NajKRtwvUvMPCcDMU1Ya2-DsxLwBrZeI_GyYQZjTdyA,6638
 kolibri/synthetic_data/benchmark/metrics.py,sha256=kBEcSyhckAC-008cs2mNpiZnqp1WJTQp5KOLTy5uyOM,3309
 kolibri/synthetic_data/benchmark/ml.py,sha256=mHIFudjNgXCLYvhhV8XkUYfLTybRa9Y4hzJ3_dsJxBw,2241
 kolibri/synthetic_data/benchmark/privacy.py,sha256=0PKRJah9S7QhIPMriiOtcvHxF683csjck4Lhmb2Vf7o,2051
-kolibri/synthetic_data/benchmark/reporting.py,sha256=oeZg9jHxl37L61ZZ5iPNuFgfwMFWr_RHrGFCwOx2dN4,4985
+kolibri/synthetic_data/benchmark/reporting.py,sha256=AKNeKEn8bxgIXOQY2UI5OaUAszwgmLAOTwKub26jyiE,6132
 kolibri/synthetic_data/benchmark/utility.py,sha256=Ql52PiyxTycjh06jq1tdD_rKcdpis-nWD_7cDUCMd8E,2239
-kolibri/synthetic_data/benchmark/utils.py,sha256=Wi2FVTOVUvaUCUIsA_J9bFBKvEYYDbfXD_8hqo-ZYpA,4880
+kolibri/synthetic_data/benchmark/utils.py,sha256=H43i-eaHS4S6a6-_x1z84Yi36LlUDw1cRsOyYCGn1Ew,5464
 kolibri/synthetic_data/benchmark/synthesizers/__init__.py,sha256=i18Pt0Z2_quop994s6T2HptWXbZnbH4GquXyC5DCppc,1063
-kolibri/synthetic_data/benchmark/synthesizers/base.py,sha256=GEuxzhmk0sk0jxeHOLW0YM9fB_y_XZU9LQ_SZ4SwsQg,1992
+kolibri/synthetic_data/benchmark/synthesizers/base.py,sha256=THwjYbodppmcxdOhHTPWmnWAH1iPfCS_W-D7vL0FN0c,2022
 kolibri/synthetic_data/benchmark/synthesizers/generate.py,sha256=V1DBF1AEk0gxDAa3LBu3zSghI-zZQ2ZzcbzPysb3OwE,7232
 kolibri/synthetic_data/benchmark/synthesizers/identity.py,sha256=Ly5uf8ZqYHF4o0xdHpQbDx-e6EkZWTfpyP6WPuI71lw,1337
 kolibri/synthetic_data/benchmark/synthesizers/independent.py,sha256=sEw6cHtpAR20koqi9UD1Zn-G5l6WYff4y_G3BhSBgfM,2114
-kolibri/synthetic_data/benchmark/synthesizers/sd.py,sha256=KGSHmYLLg7w7G7uQYd1vVmRTyX2pOukqyy_45oQTobs,3491
+kolibri/synthetic_data/benchmark/synthesizers/sd.py,sha256=BRWWPWULIty2vAoVnJnM799MjYqGFKMUVDoHKlFS2lg,5637
 kolibri/synthetic_data/benchmark/synthesizers/uniform.py,sha256=QMGg6K7Gfc6ZyC8WGJ_yquNZAEE7VjJxmvCAukE-ZnY,1665
 kolibri/task/__init__.py,sha256=9BbEOf8w2GeEtMmA8PFZe5vu_v7NSO9OQBcgZvfSsOI,66
 kolibri/task/dnn_estimator.py,sha256=h3wVQh-yMexDJiAsXDl-oED2UXx8uMadymWHO86eEG8,7685
 kolibri/task/audio/__init__.py,sha256=eWvDe5wjqDEyLXTjDp50L9S79wTBiKLdJpAVbUuUifo,104
 kolibri/task/audio/base_model.py,sha256=cqnn55k7J33H8JeQdPuLPCixIAWWIkBMDpvdG-pbtjI,9853
 kolibri/task/audio/classification/__init__.py,sha256=ab4coaEpeyuUsJTC7q81YcnWwRXOE7rbpd2wapdhVys,75
 kolibri/task/audio/classification/dnn_audio_estimator.py,sha256=NO7R87hnAZ8H3NSUfaqLn_tWA3NPRBf0Oz5fGfzeUWU,3231
@@ -688,12 +689,12 @@
 tests/synthesizer/losses/test_conditional_loss.py,sha256=0M-0-jADLCloslFs13GBqpLch_qvH7hatu3VvnaebhE,1128
 tests/synthesizer/losses/test_gradient_penalty.py,sha256=59gDBEWqfW91QiijmW1oAZJNY_r0T8lu2CINX-z_bhU,812
 tests/synthesizer/models/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tests/synthesizer/models/test_critic.py,sha256=A3Kgay2o4n0HkbIu9n1TDxRMw8G37r3HLdhb2qh0eSk,1214
 tests/synthesizer/models/test_generator.py,sha256=RI3E5_RKcCxnMSN4y0am6ar4ey-pxp5DQ8_LhHXa4ZQ,4972
 tests/synthesizer/synthesizer/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tests/synthesizer/synthesizer/test_synthesizer.py,sha256=qfsM8Okg8bW8V5NTKe657OiBFc7xKcD2dvkbqFm3_qg,4090
-kolibri_ml-1.1.83.dist-info/LICENCE.txt,sha256=eKw0ToK5-JtbuPy1tofBiXFxGgk1zhq5x0mB7gnTxc8,34572
-kolibri_ml-1.1.83.dist-info/METADATA,sha256=SKdPxdt1wurJ_ZK2QseiExQZHq2yi2sB3ZYNX4K0K9Q,4885
-kolibri_ml-1.1.83.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
-kolibri_ml-1.1.83.dist-info/top_level.txt,sha256=yZ09x7U41HE_HCr8pIum9-4eicynuHE26_L6DqI97b8,14
-kolibri_ml-1.1.83.dist-info/RECORD,,
+kolibri_ml-1.1.84.dist-info/LICENCE.txt,sha256=eKw0ToK5-JtbuPy1tofBiXFxGgk1zhq5x0mB7gnTxc8,34572
+kolibri_ml-1.1.84.dist-info/METADATA,sha256=8qle6wXJ78i8eK4xfRAs3oteZTCbezPkT0v7tk6POiw,4885
+kolibri_ml-1.1.84.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
+kolibri_ml-1.1.84.dist-info/top_level.txt,sha256=yZ09x7U41HE_HCr8pIum9-4eicynuHE26_L6DqI97b8,14
+kolibri_ml-1.1.84.dist-info/RECORD,,
```

